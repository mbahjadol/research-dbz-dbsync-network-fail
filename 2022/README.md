# SQLServer 2022 to SQLServer 2022

data flow with SQLServer 2022 as source connector and SQLServer 2022  as sink connector examples.

[<< Back to Root](../README.md)

---

### Specifications

  SQLServer version 2022
  FROM mcr.microsoft.com/mssql/server:2022-latest

---

## Topology & Architecture Design


### 1. Synchronize Topology

```
                +-----------------+
                |                 |
                |    SQLServer    |
                |      2022       |
                +---------+-------+
                          |
                          |
                          |
          +---------------v------------------+
          |                                  |
          |           Kafka Connect          |
          | (Debezium, JDBC connectors, etc) |
          |                                  |
          +---------------+------------------+
                          |
                          |
                          |
                          |
                  +-------v--------+
                  |                |
                  |   SQLServer    |
                  |      2022      |
                  +----------------+


```

We are using Docker Compose to deploy following components
* SQLServer
* Kafka
  * ZooKeeper
  * Kafka Broker
  * Kafka Connect with [Debezium](https://debezium.io/) and  [JDBC](https://debezium.io/documentation/reference/stable/connectors/jdbc.html) Connectors
* SQLServer

---

### 2. Real-time Monitoring Topology

```
+---------------------+        +---------------------+
|  Source SQL Server  |        |  Target SQL Server  |
|  (CDC enabled)      |        |  (Debezium sink)    |
+----------+----------+        +----------+----------+
           |                              ^
           |                              |
           v                              |
+---------------------+        +------------------------+
|   Debezium Connect  | -----> |     Kafka Broker       |
|  (JMX metrics open) |        |  (JMX + KafkaExporter) |
+---------------------+        +------------------------+
                |                       |
                +-----> Prometheus <----+
                            |
                            v
                        Grafana
```

##### ðŸ§­ Real-time Monitoring Goal

Add real-time monitoring for:
* Kafka consumer lag
* Debezium connector lag
* SQL Server sync latency
* System health (Kafka, Connect, Zookeeper)

Using:
* Prometheus â€” metrics collector
* Grafana â€” visualization dashboard
* Kafka Exporter â€” exports consumer lag metrics
* JMX Exporter â€” exports JVM metrics from Kafka & Connect

---

### 3. Segregation Networking Simulation Base on Real World Case

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Grafana    â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ {monitor_net}
           â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Prometheus    â”‚
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ kafka-exporter          â”‚
        â”‚ connect {bridges all}   â”‚
        â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”˜
           â”‚       â”‚           â”‚
 {source_net}  {target_net}   {kafka_net}
      â”‚            â”‚           â”‚
  source-db     target-db     kafka
      â”‚                        â”‚
 {sim_zone}             zookeeper, kafka-ui
      |
   sim-svc     
```

#### Logical Network Zone Design

| Zone         | Network | Purpose                    | Connected Components                                          |
| --------------- | -------------------------- | --------------------------| ------------------------------------------------------------- |
| ðŸ§ª **Sim Zone**     | `sim_zone` | Simulator â†” Source DB only | `sim-svc`, `source-db`                                        |
| ðŸ›¢ï¸ **Source Zone**  | `source_zone` | Connect â†” Source DB only   | `connect`, `source-db`                                        |
| ðŸŽ¯ **Target Zone**  | `target_zone` | Connect â†” Target DB only   | `connect`, `target-db`                                        |
| ðŸ”— **Kafka Zone**   | `kafka_zone` | Kafka stack                | `connect`, `zookeeper`, `kafka`, `kafka-ui`, `kafka-exporter` |
| ðŸ“ˆ **Monitor Zone** | `monitor_zone` | Monitoring stack           | `connect`, `prometheus`, `grafana`, `kafka-exporter`          |


#### Interconnection Rules

| Source                                     | Destination   | Network(s)                   | Description |
| ------------------------------------------ | ------------- | ---------------------------- | ----------- |
| `sim-svc` â†’ `source-db`                    | `sim_zone`  | For insert/update simulation |             |
| `connect` â†’ `source-db`                    | `source_zone`  | CDC source                   |             |
| `connect` â†’ `target-db`                    | `target_zone`  | JDBC sink                    |             |
| `connect` â†’ `kafka`                        | `kafka_zone`   | Message transport            |             |
| `connect` â†’ `prometheus` (metrics scrape)  | `monitor_zone` | Monitoring                   |             |
| `prometheus` â†’ `kafka-exporter`, `connect` | `monitor_zone` | Metric sources               |             |
| `grafana` â†’ `prometheus`                   | `monitor_zone` | Dashboard                    |             |


---

### Usage or Running The Simulation

All processed is almost automatically from creating container setup the connector until you can testing the flow you can only running single command and then you can follow the instruction.

#### Running

How to run:
```shell
  # Starting up
  ./start.sh

```

âŒš Just wait until all process is finished.


#### Stopping
How to stop:

```shell
# Stopping 
./stop.sh

```

---

### Monitoring The Simulation

Open in your web browser
* ðŸ‘‰ Grafana UI: http://localhost:3000
* (default login: admin / admin)
* then open **Dashboard** â†’ open **Kafka Exporter Overview**
* set **Refresh Rate by 5s** for better observe
* set time range **Last 15 Minutes** for better observe
* select **Topic** for â†’ `s1_insert_lag` and `s1_update_lag`
* then especially to observe the **Lag by Consumer Group**, you will see it continously spike and down chart, and that is expected.

You will hesitate why this architecture design feels like that, and you want to know why others simulation and test is **claim debezium sync is par of milliseconds**, you can have overview answer in [< ANSWER FOR DEBEZIUM SYNC IN MILLISECONDS >](./answer-for-dbz-in-ms.md)



## Simulating The Latency

This is our main primary test:
* Our simulation purpose here is to test whether our debezium stack layer is success or no to deliver our design synchronize process, even with loss package, but when the connection is available it will automatically deliver into our target databases.
* We will continously to observe in grafana dashboard section **Lag by Consumer Group**. 
* Our test will simulating loss package 100% for couple seconds.
* And we expected that the chart in our monitoring grafana dashboard will be spike abnormally when the simulation of package loss 100% is begin.
* Then we expected to see that in our monitoring grafana dashboard will decrease normally when the simulation latency is reset.



#### Normal **Lag by Consumer Group** Chart
![Normal_Chart](./readme_images/normal_chart.png)


### Simulating The Package Loss
We will try to simulate lost connection into our target database
```shell
  ./simulate-latency target-db loss100
```

***And then We wait for approximately 30 seconds***

then execute this:
```shell
  ./simulate-latency target-db reset
```

#### Anomaly of **Lag by Consumer Group** Chart
![Anomaly_Chart](./readme_images/anomaly_chart.png)


**We see that there was anomaly spike of consumer lag chart, that is because the sink connector is failed to connect into our target database. As our expected to this simulation**


**Then it will decrease normaly as the connection is available again**



[<< Back to Root](../README.md)